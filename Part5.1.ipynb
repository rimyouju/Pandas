{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b4d011",
   "metadata": {},
   "source": [
    "# 데이터 사전 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c929e",
   "metadata": {},
   "source": [
    "## 누락 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82b64e",
   "metadata": {},
   "source": [
    "- 데이터 분석의 정확도는 분석 데이터의 품질에 의해 좌우됨\n",
    "- 데이터의 품질을 높이기 위해거는 누락 데이터, 중복 데이터 등 오류를 수정하고 분석 목적에 맞게 변형하는 과정 필요\n",
    "- 수집한 데이터를 분석에 적합하도록 사전처리(Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c593f",
   "metadata": {},
   "source": [
    "- 데이터프레임에는 원소 데이터 값이 종종 누락되는 경우가 있음 -> NaN 데이터\n",
    "- 머신러닝 분석 모형에 데이터를 입력하기 전에 반드시 누락 데이터를 제거하거나 다른 적절한 값으로 대체하는 과정이 필요\n",
    "- 누락 데이터가 많아지면 데이터의 품질이 떨어지고, 머신러닝 분석 알고리즘을 왜곡하는 현상 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a6b15",
   "metadata": {},
   "source": [
    "##### 누락 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8965ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "# 5.1_jsnull_notnull.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f956180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: deck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5.1_jsnull_notnull.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# deck 열의 NaN 개수 계산하기\n",
    "nan_deck = df['deck'].value_counts(dropna = False)\n",
    "print(nan_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61718b",
   "metadata": {},
   "source": [
    "- isnull(): 누락 데이터면 True를 반환하고, 유효한 데이터가 존재하면 False를 반환\n",
    "- notnull(): 유효한 데이터가 존재하면 True를 반환하고, 누락 데이터면 False를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c8af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ec814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# notnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7276fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374385e0",
   "metadata": {},
   "source": [
    "##### 누락 데이터 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde7ffd",
   "metadata": {},
   "source": [
    "- 열을 삭제하면 분석 대상이 갖는 특성(변수)를 제거\n",
    "- 행을 삭제하면 분석 대상의 관측값(레코드)을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bf0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived : 0\n",
      "pclass : 0\n",
      "sex : 0\n",
      "age : 177\n",
      "sibsp : 0\n",
      "parch : 0\n",
      "fare : 0\n",
      "embarked : 2\n",
      "class : 0\n",
      "who : 0\n",
      "adult_male : 0\n",
      "deck : 688\n",
      "embark_town : 2\n",
      "alive : 0\n",
      "alone : 0\n"
     ]
    }
   ],
   "source": [
    "# 5.3_dropna.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# for 반복문으로 각 NaN의 개수 계산하기\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts() # 각 열의 NaN 개수 구하기\n",
    "    try:\n",
    "        print(col, ':', missing_count[True]) # NaN 값이 있으면 개수 출력\n",
    "    except:\n",
    "        print(col, ':', 0) # NaN 값이 없으면 0개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f6dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
      "       'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 5.2_dropna.py\n",
    "\n",
    "# NaN 값이 500개 이상인 열을 모두 삭체 - deck 열 (891개 중 688개의 NaN 값)\n",
    "df_thresh = df.dropna(axis = 1, thresh = 500)\n",
    "print(df_thresh.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f53dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행 삭제 - age 열 (891개 중 177개의 NaN 값)\n",
    "df_age = df.dropna(subset = ['age'], how = 'any', axis = 0)\n",
    "print(len(df_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999c34d",
   "metadata": {},
   "source": [
    "##### 누락 데이터 치환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62518",
   "metadata": {},
   "source": [
    "- 데이터셋의 품질을 높일 목적으로 누락 데이터를 무작정 삭제해 버린다면 어렵게 수집한 데이터를 활용하지 못하게 됨\n",
    "- 데이터 분석의 정확도는 데이터의 품질 외에도 제공되는 데이터의 양에 의해 상당한 영향을 받음\n",
    "- 데이터 중에서 일부가 누락되어 있더라도 나머지 데이터를 최대한 살려서 데이터 분석에 활용하는 것이 좋은 결과를 얻는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19f3bb",
   "metadata": {},
   "source": [
    "- 누락 데이터를 바꿔서 대체할 값으로는 데이터의 분포와 특성을 잘 나타낼 수 있는 평균값, 최빈값 등을 활용\n",
    "- fillna() 메서드는 새로운 객체를 반환하기 때문에 원본 객체를 변경하려면 inplace = True 옵션을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44125f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 5.3_replace_nan.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력(5행에 NaN 값)\n",
    "print(df['age'].head(10))\n",
    "print('\\n')\n",
    "\n",
    "# age 열의 NaN 값을 다른 나이 데이터의 평균으로 변경하기\n",
    "mean_age = df['age'].mean(axis = 0) # age 열의 평균 계산 (NaN 값 제외)\n",
    "df['age'].fillna(mean_age, inplace = True)\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력 (5행에 NaN 값이 평균으로 대체)\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50c2d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "Southampton\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5.4_replace_nan2.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "# embark_town 열의 NaN 값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embark_town'].value_counts(dropna = True).idxmax()\n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(most_freq, inplace = True)\n",
    "\n",
    "# enbark_town 열 829행의 NaN 데이터 출력 (NaN 값이 most_freq 값으로 대체)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a3e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5.5_replace_nan3.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "# embark_town 열의 NaN 값을 바로 앞에 있는 828행의 값으로 변경하기\n",
    "df['embark_town'].fillna(method = 'ffill', inplace = True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2bf922",
   "metadata": {},
   "source": [
    "### 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8d31e",
   "metadata": {},
   "source": [
    "- 데이터프레임에서 각 행은 분석 대상이 가지고 있는 모든 속성(변수)에 대한 관측값(레코드)을 뜻함\n",
    "- 하나의 데이터셋에서 동일한 관측값이 2개 이상 중복되는 경우 중복 데이터를 찾아서 삭제해야 함     \n",
    "-> 동일한 대상이 중복으로 존재하는 것이 분석 결과를 왜곡함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdba76",
   "metadata": {},
   "source": [
    "##### 중복 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1848c6",
   "metadata": {},
   "source": [
    "- 동일한 관측값이 중복되는지 여부, 즉 행의 레코드가 중복되는지 여부를 확인하려면 duplicated() 메서드를 이용\n",
    "- 전에 나온 행들과 비교하여 중복되는 행이면 True를 반환하고, 처음 나오는 행에 대해서는 False를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9713ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.6_duplicated.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1' : ['a', 'a', 'b', 'a', 'b'],\n",
    "                   'c2' : [1, 1, 1, 2, 2],\n",
    "                   'c3' : [1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임 전체 행 데이터 중에서 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9909be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3563f8",
   "metadata": {},
   "source": [
    "##### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a829c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.7_drop_duplicates.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1' : ['a', 'a', 'b', 'a', 'b'],\n",
    "                   'c2' : [1, 1, 1, 2, 2],\n",
    "                   'c3' : [1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임에서 중복 행 제거\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a08eaa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "# c2, c3열을 기준으로 중복 행 제거\n",
    "df3 = df.drop_duplicates(subset = ['c2', 'c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa1bbd",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46b9b0",
   "metadata": {},
   "source": [
    "- 동일한 대상을 표현하는 방법에 차이가 있으면, 분석의 정확도는 현저히 낮아짐\n",
    "- 데이터 포맷을 일관성 있게 표준화하는 작업이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1693f",
   "metadata": {},
   "source": [
    "#### 단위 확산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778cacf",
   "metadata": {},
   "source": [
    "- 같은 데이터셋 안에서 서로 다른 측정 단위를 사용한다면, 전체 데이터의 일관성 측면에서 문제 발생\n",
    "- 측정 단위를 동일하게 맞춰야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42af506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name       kpl  \n",
      "0       1  chevrolet chevelle malibu  7.652571  \n",
      "1       1          buick skylark 320  6.377143  \n",
      "2       1         plymouth satellite  7.652571  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name   kpl  \n",
      "0       1  chevrolet chevelle malibu  7.65  \n",
      "1       1          buick skylark 320  6.38  \n",
      "2       1         plymouth satellite  7.65  \n"
     ]
    }
   ],
   "source": [
    "# 5.8_unit_conversion.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('/Users/youju/Downloads/5674-833_4th/part5/auto-mpg.csv', header = None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'model year', 'origin', 'name']\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환 (mpg_to_kpl = 0.425)\n",
    "mpg_to_kpl = 1.60934 / 3.78541\n",
    "\n",
    "# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# kpl 열을 소수점 아래 둘째자리에서 반올림\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81feab93",
   "metadata": {},
   "source": [
    "#### 자료형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8043357",
   "metadata": {},
   "source": [
    "- 숫자가 문자열(object)로 저장된 경우 숫자형(int 또는 float)으로 변환\n",
    "- dtypes 속성을 사용하여 데이터프레임을 구성하는 각 열의 자료형을 확인\n",
    "- dtypes 속성 대신 info() 메서드를 사용해도 각 열의 자료형 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfdc8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower       object\n",
      "weight          float64\n",
      "acceleration    float64\n",
      "model year        int64\n",
      "origin            int64\n",
      "name             object\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.9_datatype_conversion.py\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('/Users/youju/Downloads/5674-833_4th/part5/auto-mpg.csv', header = None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'model year', 'origin', 'name']\n",
    "\n",
    "# 각 열의 자료형 확인\n",
    "print(df.dtypes)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce95b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# horsepower 열의 고유값 확인\n",
    "print(df['horsepower'].unique())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d63057ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터('?') 삭제\n",
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # '?'을 np.nan으로 변경\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True) # 누락 데이터 행 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float') # 문자형을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 자료형 확인\n",
    "print(df['horsepower'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c8d6a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n",
      "['USA' 'JPN' 'EU']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# origin 열의 고유값 확인\n",
    "print(df['origin'].unique())\n",
    "\n",
    "# 정수형 데이터를 문자열 데이터로 변환\n",
    "df['origin'].replace({1 : 'USA', 2 : 'EU', 3 : 'JPN'}, inplace = True)\n",
    "\n",
    "# origin 열의 고유값과 자료형 확인\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09d0460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 범주형으로 변환\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].dtypes)\n",
    "\n",
    "# 범주형을 문자열로 다시 변환\n",
    "df['origin'] = df['origin'].astype('str')\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611c7443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155    75\n",
      "199    76\n",
      "167    75\n",
      "Name: model year, dtype: int64\n",
      "152    75\n",
      "371    82\n",
      "16     70\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year 열의 정수형을 범주형으로 변환\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print(df['model year'].sample(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

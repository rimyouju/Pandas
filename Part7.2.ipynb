{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2293a344",
   "metadata": {},
   "source": [
    "### 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb0c8b",
   "metadata": {},
   "source": [
    "분류 알고리즘\n",
    "- 예측하려는 대상의 속성(설명 변수)을 입력 받고, 목표 변수가 갖고 있는 카테고리(범주형) 값 중에서 어느 한 값으로 분류하여 예측\n",
    "- 훈련 데이터에 목표 변수 값(0 또는 1)을 함께 입략 -> 지도학습 유형에 속하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfedee82",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec8ef78",
   "metadata": {},
   "source": [
    "KNN(K-Nearest-Neighbors)\n",
    "- k개의 가까운 이웃\n",
    "- 새로운 관측값이 주어지면 기존 데이터 중에서 가장 속성이 비슷한 k개의 이웃을 먼저 찾음\n",
    "- 가까운 이웃들이 갖고 있는 목표 값과 같은 값으로 분류하여 예측\n",
    "- k값에 따라 예측 정확도가 달라짐 -> 적절한 k값을 찾는 것이 매우 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e46e89",
   "metadata": {},
   "source": [
    "Step 1 - 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daea0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "# 7.4_knn_classification.py\n",
    "\n",
    "# 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비 - seaborn에서 제공하는 titanic 데이터셋 가져오기\n",
    "'''\n",
    "\n",
    "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5e8da",
   "metadata": {},
   "source": [
    "Step 2 - 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb801e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 2] 데이터 탐색/전처리\n",
    "'''\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1148747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone']\n"
     ]
    }
   ],
   "source": [
    "# NaN 값이 많은 deck 열 삭제, embarked와 내용이 겹치는 embark_town 열 삭제\n",
    "rdf = df.drop(['deck', 'embark_town'], axis = 1)\n",
    "print(rdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a75ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "rdf = rdf.dropna(subset = ['age'], how = 'any', axis = 0)\n",
    "print(len(rdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d70d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "\n",
      "\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   714.000000  714.000000   714  714.000000  714.000000  714.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   453         NaN         NaN         NaN   \n",
      "mean      0.406162    2.236695   NaN   29.699118    0.512605    0.431373   \n",
      "std       0.491460    0.838250   NaN   14.526497    0.929783    0.853289   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    1.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    2.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    1.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    5.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male alive alone  \n",
      "count   714.000000      712    714  714        714   714   714  \n",
      "unique         NaN        3      3    3          2     2     2  \n",
      "top            NaN        S  Third  man       True    no  True  \n",
      "freq           NaN      554    355  413        413   424   404  \n",
      "mean     34.694514      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "std      52.918930      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "min       0.000000      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "25%       8.050000      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "50%      15.741700      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "75%      33.375000      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "max     512.329200      NaN    NaN  NaN        NaN   NaN   NaN  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embarked 열의 NaN 값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts(dropna = True).idxmax()\n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "print(rdf.describe(include = 'all'))\n",
    "print('\\n')\n",
    "\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7037f",
   "metadata": {},
   "source": [
    "Step 3 - 속성 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f89064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch embarked\n",
      "0         0       3    male  22.0      1      0        S\n",
      "1         1       1  female  38.0      1      0        C\n",
      "2         1       3  female  26.0      0      0        S\n",
      "3         1       1  female  35.0      1      0        S\n",
      "4         0       3    male  35.0      0      0        S\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 3] 분석에 사용할 속성 선택\n",
    "'''\n",
    "\n",
    "# 분석에 활용할 열(속성) 선택\n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0112c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
      "0         0       3  22.0      1      0       0     1       0       0       1\n",
      "1         1       1  38.0      1      0       1     0       1       0       0\n",
      "2         1       3  26.0      0      0       1     0       0       0       1\n",
      "3         1       1  35.0      1      0       1     0       0       0       1\n",
      "4         0       3  35.0      0      0       0     1       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1, inplace = True)\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90f746",
   "metadata": {},
   "source": [
    "Step 4 - 훈련/검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870e7d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수: (499, 9)\n",
      "test data 개수: (215, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 4] 데이터셋 구분 - 훈련용(train data) / 검증용(test data0\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X = ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male',\n",
    "         'town_C', 'town_Q', 'town_S']] # 설명 번수 X\n",
    "y = ndf['survived'] # 예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화(nomalization)\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 개수:', X_train.shape)\n",
    "print('test data 개수:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe225ef5",
   "metadata": {},
   "source": [
    "분류 모형의 예측력을 평가하는 지표\n",
    "- Confussion Matrix : 모형이 예측하는 값에는 두 가지(True / False)가 있고, 각 예측값은 실제로 True이거나 False일 수 있음\n",
    "\n",
    "- 정확도(Precision) : True로 예측한 분석대상 중에서 실제 값이 True인 비율을 말하며, 모형의 정확성을 나타내는 지표               \n",
    "정확도가 높다 -> False Positive(실제 False를 True로 잘못 예측) 오류가 낮다\n",
    "\n",
    "- 재현율(Recall) : 실제 값이 True인 분석대상 중에서 True로 예측하여 모형이 적중한 비율; 모형의 완전성을 나타내는 지표            \n",
    "재현율이 높다 -> False Negative(실제 True를 False로 잘못 예측) 오류가 낮다\n",
    "\n",
    "- F1 지표(F1-score) : 정확도와 재현율이 균등하게 반영될 수 있도록 정확도와 재현율의 조화 평균을 계산한 값; 모형의 예측력을 종합적으로 평가하는 지표            \n",
    "값이 높을수록 분류 모형의 예측력이 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0b139",
   "metadata": {},
   "source": [
    "Step 5 - 모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0e4350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 1 1 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 5] KNN 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 KNN 분류 모형 가져오기\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모형 객체 생성(k = 5로 설정)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측(분류)\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72635af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  14]\n",
      " [ 24  66]]\n"
     ]
    }
   ],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(knn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "394a3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       125\n",
      "           1       0.82      0.73      0.78        90\n",
      "\n",
      "    accuracy                           0.82       215\n",
      "   macro avg       0.82      0.81      0.82       215\n",
      "weighted avg       0.82      0.82      0.82       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모형 성능 평가 - 평가 지표 계산\n",
    "knn_report = metrics.classification_report(y_test, y_hat)\n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e20760",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b696746",
   "metadata": {},
   "source": [
    "SVM(Support Vector MAchine)\n",
    "- 벡터(vector) 개념을 가져와서 사용\n",
    "- 데이터셋의 여러 속성을 나타내는 데이터프레임의 각 열은 열 벡터 형태로 구현됨\n",
    "- 열 벡터들이 각각 고유의 축을 갖는 벡터 공간을 만드는데, 분석 대상이 되는 개별 관측값은 모든 속성(열 벡터)에 관한 값을 해당 축의 좌표로 표시하여 벡터 공간에서의 위치를 나타냄\n",
    "- 속성(열 벡터)이 2개 존재하는 데이터셋은 2차원 평면 공간에 좌표로 표시\n",
    "- 속성이 3개이면 3차원 공간에 표시\n",
    "- 4차 이상의 고차원 벡터 공간의 좌표를 사용하는 것도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1981ccd",
   "metadata": {},
   "source": [
    "- SVM 모형은 벡터 공간에 위치한 훈련 데이터의 좌표와 각 데이터가 어떤 분류 값을 가져야 하는지 정답을 입력 받아서 학습\n",
    "- 같은 분류 값을 갖는 데이터끼리 같은 공간에 위치하도록 벡터 공간을 여러 조각으로 나눌 수 있다면, 새로운 데이터에 대해서도 어느 공간에 위치하는지 분류 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d812cc3",
   "metadata": {},
   "source": [
    "##### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3422e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수: (499, 9)\n",
      "test data 개수: (215, 9)\n"
     ]
    }
   ],
   "source": [
    "# 7.5_svm_classification.py\n",
    "\n",
    "# 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1] - 데이터 준비 / 기본 설정\n",
    "'''\n",
    "\n",
    "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "'''\n",
    "[Step 2] 데이터 탐색 / 전처리\n",
    "'''\n",
    "\n",
    "# NaN 값이 많은 deck 열 삭제, embarked와 내용이 겹치는 embark_town 열 삭제\n",
    "rdf = df.drop(['deck', 'embark_town'], axis = 1)\n",
    "\n",
    "# age 열에 나이 데이터가 없는 모든 행 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "rdf = rdf.dropna(subset = ['age'], how = 'any', axis = 0)\n",
    "\n",
    "# embarked 열의 NaN 값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts(dropna = True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "'''\n",
    "[Step 3] 분석에 사용할 속성 선택\n",
    "'''\n",
    "\n",
    "# 분석에 활용할 열(속성) 선택\n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "\n",
    "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1, inplace = True)\n",
    "\n",
    "'''\n",
    "[Step 4] 데이터셋 구현 - 훈련용(train data) / 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수)선택\n",
    "X = ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male',\n",
    "         'town_C', 'town_Q', 'town_S']] # 독립 변수 X\n",
    "y = ndf['survived'] # 종속 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화(normalization)\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 개수:', X_train.shape)\n",
    "print('test data 개수:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e3a73",
   "metadata": {},
   "source": [
    "##### 모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619bc3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 5] SVM 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
    "from sklearn import svm\n",
    "\n",
    "# 모형 객체 생성(kernel = 'rdf' 적용)\n",
    "svm_model = svm.SVC(kernel = 'rbf')\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat 예측(분류)\n",
    "y_hat = svm_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b18c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   5]\n",
      " [ 35  55]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86       125\n",
      "           1       0.92      0.61      0.73        90\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.85      0.79      0.80       215\n",
      "weighted avg       0.83      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(svm_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가\n",
    "svm_report = metrics.classification_report(y_test, y_hat)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd254e81",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e3063",
   "metadata": {},
   "source": [
    "의사결정 트리\n",
    "- 컴퓨터 알고리즘에서 즐겨 사용하는 트리(tree) 구조를 사용하고, 각 분기점(node)에는 분석 대상의 속성(설명 변수)들이 위치\n",
    "- 각 분기점마다 목표 값을 가장 잘 분류할 수 있는 속성을 찾아서 배치하고, 해당 속성이 갖는 값을 이용해서 새로운 가지(branch)를 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98181d4",
   "metadata": {},
   "source": [
    "- 각 분기점에서 최적의 속성을 선택할 때는 해당 속성을 기준으로 분류한 값들이 구분되는 정도를 측정\n",
    "- 다른 종류의 값들이 섞여 있는 정도를 나타내는 Entropy를 주로 활용\n",
    "- Entropy가 낮을수록 분류가 잘 된 것 -> Entropy가 일정 수준 이하로 낮아질 때까지 앞의 과정을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1570a2b5",
   "metadata": {},
   "source": [
    "데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b29d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  clump  cell_size  cell_shape  adhesion  epithlial bare_nuclei  \\\n",
      "0  1000025      5          1           1         1          2           1   \n",
      "1  1002945      5          4           4         5          7          10   \n",
      "2  1015425      3          1           1         1          2           2   \n",
      "3  1016277      6          8           8         1          3           4   \n",
      "4  1017023      4          1           1         3          2           1   \n",
      "\n",
      "   chromatin  normal_nucleoli  mitoses  class  \n",
      "0          3                1        1      2  \n",
      "1          3                2        1      2  \n",
      "2          3                1        1      2  \n",
      "3          3                7        1      2  \n",
      "4          3                1        1      2  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               699 non-null    int64 \n",
      " 1   clump            699 non-null    int64 \n",
      " 2   cell_size        699 non-null    int64 \n",
      " 3   cell_shape       699 non-null    int64 \n",
      " 4   adhesion         699 non-null    int64 \n",
      " 5   epithlial        699 non-null    int64 \n",
      " 6   bare_nuclei      699 non-null    object\n",
      " 7   chromatin        699 non-null    int64 \n",
      " 8   normal_nucleoli  699 non-null    int64 \n",
      " 9   mitoses          699 non-null    int64 \n",
      " 10  class            699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
      "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
      "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
      "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial   chromatin  normal_nucleoli     mitoses       class  \n",
      "count  699.000000  699.000000       699.000000  699.000000  699.000000  \n",
      "mean     3.216023    3.437768         2.866953    1.589413    2.689557  \n",
      "std      2.214300    2.438364         3.053634    1.715078    0.951273  \n",
      "min      1.000000    1.000000         1.000000    1.000000    2.000000  \n",
      "25%      2.000000    2.000000         1.000000    1.000000    2.000000  \n",
      "50%      2.000000    3.000000         1.000000    1.000000    2.000000  \n",
      "75%      4.000000    5.000000         4.000000    1.000000    4.000000  \n",
      "max     10.000000   10.000000        10.000000   10.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "# 7.6_tree_classification.py\n",
    "\n",
    "# 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "'''\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "              'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28396e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '10' '2' '4' '3' '9' '7' '?' '5' '8' '6']\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.830000e+02  683.000000  683.000000  683.000000  683.000000   \n",
      "mean   1.076720e+06    4.442167    3.150805    3.215227    2.830161   \n",
      "std    6.206440e+05    2.820761    3.065145    2.988581    2.864562   \n",
      "min    6.337500e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.776170e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171795e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238705e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial  bare_nuclei   chromatin  normal_nucleoli     mitoses  \\\n",
      "count  683.000000   683.000000  683.000000       683.000000  683.000000   \n",
      "mean     3.234261     3.544656    3.445095         2.869693    1.603221   \n",
      "std      2.223085     3.643857    2.449697         3.052666    1.732674   \n",
      "min      1.000000     1.000000    1.000000         1.000000    1.000000   \n",
      "25%      2.000000     1.000000    2.000000         1.000000    1.000000   \n",
      "50%      2.000000     1.000000    3.000000         1.000000    1.000000   \n",
      "75%      4.000000     6.000000    5.000000         4.000000    1.000000   \n",
      "max     10.000000    10.000000   10.000000        10.000000   10.000000   \n",
      "\n",
      "            class  \n",
      "count  683.000000  \n",
      "mean     2.699854  \n",
      "std      0.954592  \n",
      "min      2.000000  \n",
      "25%      2.000000  \n",
      "50%      2.000000  \n",
      "75%      4.000000  \n",
      "max      4.000000  \n"
     ]
    }
   ],
   "source": [
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['bare_nuclei'].unique()) # bare_nuclei 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True) # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True) # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int') # 문자열을 정수형으로 변환\n",
    "\n",
    "print(df.describe()) # 데이터 통계 요약정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2525c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수:  (478, 9)\n",
      "test data 개수:  (205, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "        'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']]  # 설명 변수 X\n",
    "y = df['class']  # 예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d0112",
   "metadata": {},
   "source": [
    "모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b424243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "609cc0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127   4]\n",
      " [  2  72]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.98       131\n",
      "           4       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd61a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
